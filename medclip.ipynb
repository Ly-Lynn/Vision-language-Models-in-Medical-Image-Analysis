{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f40c805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep 23 00:04:08 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.85                 Driver Version: 555.85         CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650 Ti   WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   46C    P8              4W /   50W |       0MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5789be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/RyanWangZf/MedCLIP.git\n",
    "%pip install pyarrow==14.0.2 datasets==2.16.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e35cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install kagglehub datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "654bfdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Conda\\envs\\entrep\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"d:\\Conda\\envs\\entrep\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"d:\\Conda\\envs\\entrep\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"D:\\Temp\\ipykernel_19840\\3805267577.py\", line 4, in <module>\n",
      "    import pandas as pd\n",
      "  File \"d:\\Conda\\envs\\entrep\\pandas\\__init__.py\", line 38, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"d:\\Conda\\envs\\entrep\\pandas\\compat\\__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"d:\\Conda\\envs\\entrep\\pandas\\compat\\pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"d:\\Conda\\envs\\entrep\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"d:\\Conda\\envs\\entrep\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"D:\\Temp\\ipykernel_19840\\3805267577.py\", line 4, in <module>\n",
      "    import pandas as pd\n",
      "  File \"d:\\Conda\\envs\\entrep\\pandas\\__init__.py\", line 61, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"d:\\Conda\\envs\\entrep\\pandas\\core\\api.py\", line 9, in <module>\n",
      "    from pandas.core.dtypes.dtypes import (\n",
      "  File \"d:\\Conda\\envs\\entrep\\pandas\\core\\dtypes\\dtypes.py\", line 24, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"d:\\Conda\\envs\\entrep\\lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18e43163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\codePJ\\uit-final-thesis\\Vision-language-Models-in-Medical-Image-Analysis\\MedCLIP\n"
     ]
    }
   ],
   "source": [
    "%cd MedCLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec14d2ba",
   "metadata": {},
   "source": [
    "# Chexpert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a2cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "\n",
    "# # Download the dataset and explore available files\n",
    "# print(\"Downloading CheXpert dataset...\")\n",
    "# dataset_path = kagglehub.dataset_download('ashery/chexpert')\n",
    "# print(f\"Dataset downloaded to: {dataset_path}\")\n",
    "\n",
    "chexpert_val_csv = kagglehub.load_dataset(\n",
    "    KaggleDatasetAdapter.PANDAS,\n",
    "    \"ashery/chexpert\",\n",
    "    \"valid.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6ab029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chexpert_5x200(chexpert_val_csv):\n",
    "\n",
    "    condition_columns = ['Atelectasis', 'Cardiomegaly', 'Edema', 'Pleural Effusion', 'Consolidation']\n",
    "\n",
    "    other_cols = [col for col in condition_columns if col != 'Atelectasis']\n",
    "    unique_Atelectasis = chexpert_val_csv[(chexpert_val_csv['Atelectasis'] != 0) & \n",
    "                                    (chexpert_val_csv[other_cols] == 0).all(axis=1)]\n",
    "\n",
    "    other_cols = [col for col in condition_columns if col != 'Cardiomegaly']\n",
    "    unique_Cardiomegaly = chexpert_val_csv[(chexpert_val_csv['Cardiomegaly'] != 0) & \n",
    "                                    (chexpert_val_csv[other_cols] == 0).all(axis=1)]\n",
    "\n",
    "    other_cols = [col for col in condition_columns if col != 'Edema']\n",
    "    unique_Edema = chexpert_val_csv[(chexpert_val_csv['Edema'] != 0) & \n",
    "                            (chexpert_val_csv[other_cols] == 0).all(axis=1)]\n",
    "\n",
    "    other_cols = [col for col in condition_columns if col != 'Pleural Effusion']\n",
    "    unique_PleuralEffusion = chexpert_val_csv[(chexpert_val_csv['Pleural Effusion'] != 0) & \n",
    "                                        (chexpert_val_csv[other_cols] == 0).all(axis=1)]\n",
    "\n",
    "    other_cols = [col for col in condition_columns if col != 'Consolidation']\n",
    "    unique_Consolidation = chexpert_val_csv[(chexpert_val_csv['Consolidation'] != 0) & \n",
    "                                    (chexpert_val_csv[other_cols] == 0).all(axis=1)]\n",
    "    return unique_Atelectasis, unique_Cardiomegaly, unique_Edema, unique_PleuralEffusion, unique_Consolidation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb70807",
   "metadata": {},
   "source": [
    "# MIMIC CXR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2748df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"itsanmolgupta/mimic-cxr-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006ee809",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb656b15",
   "metadata": {},
   "source": [
    "# COVID 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a0440a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\codePJ\\uit-final-thesis\\Vision-language-Models-in-Medical-Image-Analysis\\MedCLIP\n"
     ]
    }
   ],
   "source": [
    "%cd MedCLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa64e706",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46209977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/tawsifurrahman/covid19-radiography-database?dataset_version_number=5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 10.0M/778M [00:02<03:07, 4.29MB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m covid_data_path \u001b[38;5;241m=\u001b[39m \u001b[43mkagglehub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_download\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtawsifurrahman/covid19-radiography-database\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Conda\\envs\\entrep\\lib\\site-packages\\kagglehub\\datasets.py:43\u001b[0m, in \u001b[0;36mdataset_download\u001b[1;34m(handle, path, force_download)\u001b[0m\n\u001b[0;32m     41\u001b[0m h \u001b[38;5;241m=\u001b[39m parse_dataset_handle(handle)\n\u001b[0;32m     42\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading Dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;241m.\u001b[39mto_url()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m\"\u001b[39m, extra\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mEXTRA_CONSOLE_BLOCK})\n\u001b[1;32m---> 43\u001b[0m path, _ \u001b[38;5;241m=\u001b[39m \u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_resolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "File \u001b[1;32md:\\Conda\\envs\\entrep\\lib\\site-packages\\kagglehub\\registry.py:28\u001b[0m, in \u001b[0;36mMultiImplRegistry.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m impl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impls):\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mis_supported(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m         fails\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mtype\u001b[39m(impl)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32md:\\Conda\\envs\\entrep\\lib\\site-packages\\kagglehub\\resolver.py:29\u001b[0m, in \u001b[0;36mResolver.__call__\u001b[1;34m(self, handle, path, force_download)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mself\u001b[39m, handle: T, path: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, force_download: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     17\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Optional[\u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resolves a handle into a path with the requested file(s) and the resource's version number.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m        Some cases where version number might be missing: Competition datasource, API-based models.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     path, version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# Note handles are immutable, so _resolve() could not have altered our reference\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     register_datasource_access(handle, version)\n",
      "File \u001b[1;32md:\\Conda\\envs\\entrep\\lib\\site-packages\\kagglehub\\http_resolver.py:130\u001b[0m, in \u001b[0;36mDatasetHttpResolver._resolve\u001b[1;34m(self, h, path, force_download)\u001b[0m\n\u001b[0;32m    127\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(archive_path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# First, we download the archive.\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m \u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marchive_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m _extract_archive(archive_path, out_path)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Delete the archive\u001b[39;00m\n",
      "File \u001b[1;32md:\\Conda\\envs\\entrep\\lib\\site-packages\\kagglehub\\clients.py:217\u001b[0m, in \u001b[0;36mKaggleApiV1Client.download_file\u001b[1;34m(self, path, out_file, resource_handle, cached_path, extract_auto_compressed_file)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 217\u001b[0m     \u001b[43m_download_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_read\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_object\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hash_object:\n\u001b[0;32m    220\u001b[0m     actual_md5_hash \u001b[38;5;241m=\u001b[39m to_b64_digest(hash_object)\n",
      "File \u001b[1;32md:\\Conda\\envs\\entrep\\lib\\site-packages\\kagglehub\\clients.py:276\u001b[0m, in \u001b[0;36m_download_file\u001b[1;34m(response, out_file, size_read, total_size, hash_object)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mtotal_size, initial\u001b[38;5;241m=\u001b[39msize_read, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, unit_divisor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m progress_bar:\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(out_file, open_mode) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 276\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_content(CHUNK_SIZE):\n\u001b[0;32m    277\u001b[0m             f\u001b[38;5;241m.\u001b[39mwrite(chunk)\n\u001b[0;32m    278\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m hash_object:\n",
      "File \u001b[1;32md:\\Conda\\envs\\entrep\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32md:\\Conda\\envs\\entrep\\urllib3\\response.py:1066\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1066\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1068\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m   1069\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[1;32md:\\Conda\\envs\\entrep\\urllib3\\response.py:955\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    952\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[1;32m--> 955\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    957\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32md:\\Conda\\envs\\entrep\\urllib3\\response.py:879\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    876\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 879\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[0;32m    889\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32md:\\Conda\\envs\\entrep\\urllib3\\response.py:862\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[1;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32md:\\Conda\\envs\\entrep\\lib\\http\\client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32md:\\Conda\\envs\\entrep\\lib\\socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Conda\\envs\\entrep\\lib\\ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32md:\\Conda\\envs\\entrep\\lib\\ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "covid_data_path = kagglehub.dataset_download('tawsifurrahman/covid19-radiography-database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0294e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_covid_csv(covid_lst, non_covid_lst):\n",
    "    df = pd.DataFrame(columns=['imgpath', 'COVID', 'Normal'])\n",
    "    for covid in covid_lst:\n",
    "        new_row = pd.DataFrame({'imgpath': [covid], 'COVID': [1], 'Normal': [0]})\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "    for non_covid in non_covid_lst:\n",
    "        new_row = pd.DataFrame({'imgpath': [non_covid], 'COVID': [0], 'Normal': [1]})\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "    df.to_csv('local_data/covid-test-meta.csv', index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca3edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_prompt = \"the presence of patchy or confluent, bandlike ground-glass opacity or consolidation in a peripheral and mid to lower lung zone distribution\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8caa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data_path = os.path.join(covid_data_path, 'COVID-19_Radiography_Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93103b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0597cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\n",
    "    covid_data_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc7defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "viral_pneumonia_path = os.path.join(\n",
    "        covid_data_path,\n",
    "        'Viral Pneumonia',\n",
    "        'images'\n",
    ")\n",
    "viral_pneumonia_path_list = [os.path.join(viral_pneumonia_path, f) \n",
    "                            for f in os.listdir(viral_pneumonia_path)]\n",
    "\n",
    "lung_opacity_path = os.path.join(\n",
    "        covid_data_path,\n",
    "        'Lung_Opacity',\n",
    "        'images'\n",
    ")\n",
    "lung_opacity_path_list = [os.path.join(lung_opacity_path, f)\n",
    "                         for f in os.listdir(lung_opacity_path)]\n",
    "\n",
    "normal_path = os.path.join( \n",
    "        covid_data_path,\n",
    "        'Normal',\n",
    "        'images'\n",
    ")\n",
    "normal_path_list = [os.path.join(normal_path, f)\n",
    "                   for f in os.listdir(normal_path)]\n",
    "\n",
    "covid_path = os.path.join(\n",
    "        covid_data_path,\n",
    "        'COVID',\n",
    "        'images'\n",
    ")\n",
    "covid_path_list = [os.path.join(covid_path, f)\n",
    "                  for f in os.listdir(covid_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d69e5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_csv = create_covid_csv(covid_path_list, \n",
    "                            viral_pneumonia_path_list + lung_opacity_path_list + normal_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3089bda1",
   "metadata": {},
   "source": [
    "## Zero shot classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5bfe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medclip import MedCLIPModel, MedCLIPVisionModelViT, PromptClassifier\n",
    "from medclip.dataset import ZeroShotImageDataset, ZeroShotImageCollator\n",
    "from medclip.evaluator import Evaluator\n",
    "from medclip.prompts import generate_covid_class_prompts\n",
    "from medclip.modeling_medclip import PromptClassifier\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5c791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate COVID class prompts\n",
    "covid_prompts = generate_covid_class_prompts(n=5)\n",
    "print(\"COVID class prompts:\", covid_prompts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95820382",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['COVID', 'Normal']\n",
    "\n",
    "covid_clf_dataset = ZeroShotImageDataset(\n",
    "    datalist=['covid-test'],\n",
    "    class_names=class_names,\n",
    "    imgtransform=None\n",
    ")\n",
    "\n",
    "# Create the collator with COVID prompts\n",
    "covid_collator = ZeroShotImageCollator(\n",
    "    mode='binary',\n",
    "    cls_prompts=covid_prompts,\n",
    "    n_prompt=5\n",
    ")\n",
    "\n",
    "covid_dataloader= DataLoader(\n",
    "    covid_clf_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0,  # Set to 0 to avoid multiprocessing issues\n",
    "    collate_fn=covid_collator\n",
    ")\n",
    "\n",
    "resnet_clf = MedCLIPModel(vision_cls=MedCLIPVisionModelViT)\n",
    "resnet_clf.from_pretrained()\n",
    "resnet_clf.cuda()\n",
    "\n",
    "covid_classifier = PromptClassifier(\n",
    "    medclip_model=resnet_clf,\n",
    "    ensemble=True  \n",
    ")\n",
    "\n",
    "evaluator = Evaluator(\n",
    "    medclip_clf=covid_classifier,\n",
    "    eval_dataloader=covid_dataloader_fixed,\n",
    "    mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651c23d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing the dataloader...\")\n",
    "test_batch = next(iter(covid_dataloader))\n",
    "print(\"Batch keys:\", test_batch.keys())\n",
    "print(\"Pixel values shape:\", test_batch['pixel_values'].shape)\n",
    "print(\"Labels shape:\", test_batch['labels'].shape)\n",
    "print(\"Prompt inputs keys:\", test_batch['prompt_inputs'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa638d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRunning evaluation...\")\n",
    "results = evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f053fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Results: {results}\")\n",
    "print(f\"accuracy: {results['acc']}\")\n",
    "print(f\"precision: {results['precision']}\")\n",
    "print(f\"recall: {results['recall']}\")\n",
    "print(f\"f1_score: {results['f1-score']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9324987d",
   "metadata": {},
   "source": [
    "# RNSA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7b2f1b",
   "metadata": {},
   "source": [
    "## Zero shot classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86a92717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\codePJ\\uit-final-thesis\\Vision-language-Models-in-Medical-Image-Analysis\\MedCLIP\n"
     ]
    }
   ],
   "source": [
    "%cd MedCLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23e1a6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medclip import MedCLIPModel, MedCLIPVisionModelViT, PromptClassifier, MedCLIPVisionModel\n",
    "from medclip.dataset import ZeroShotImageDataset, ZeroShotImageCollator\n",
    "from medclip.evaluator import Evaluator\n",
    "from medclip.prompts import generate_rsna_class_prompts\n",
    "from medclip.modeling_medclip import PromptClassifier\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9827fe0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 5 num of prompts for Pneumonia from total 312\n",
      "RSNA class prompts: {'Pneumonia': ['small bacterial at the left lung zone', 'early viral at the bilateral lung bases', 'early viral at the mid lung zone', 'focal mycoplasma at the lung bases', 'multifocal bacterial at the right lung base']}\n"
     ]
    }
   ],
   "source": [
    "# Generate RSNA class prompts\n",
    "rsna_prompts = generate_rsna_class_prompts(n=5)\n",
    "print(\"RSNA class prompts:\", rsna_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "187a9df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data from ./local_data/rsna-balanced-test-meta.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Conda\\envs\\entrep\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "d:\\Conda\\envs\\entrep\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Conda\\envs\\entrep\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "d:\\Conda\\envs\\entrep\\lib\\site-packages\\transformers\\modeling_utils.py:399: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Download pretrained model from: https://storage.googleapis.com/pytrial/medclip-pretrained.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\codePJ\\uit-final-thesis\\Vision-language-Models-in-Medical-Image-Analysis\\MedCLIP\\medclip\\modeling_medclip.py:184: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(os.path.join(input_dir, constants.WEIGHTS_NAME))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model weight from: ./pretrained/medclip-resnet\n"
     ]
    }
   ],
   "source": [
    "class_names = ['Pneumonia', 'Normal']\n",
    "\n",
    "# Use the DICOM-compatible dataset class for RSNA data\n",
    "rsna_clf_dataset = ZeroShotImageDataset(\n",
    "    datalist=['rsna-balanced-test'],\n",
    "    class_names=class_names,\n",
    "    imgtransform=None\n",
    ")\n",
    "\n",
    "# Create the collator with RSNA prompts\n",
    "rsna_collator = ZeroShotImageCollator(\n",
    "    mode='binary',\n",
    "    cls_prompts=rsna_prompts,\n",
    "    n_prompt=5\n",
    ")\n",
    "\n",
    "rsna_dataloader= DataLoader(\n",
    "    rsna_clf_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # Set to 0 to avoid multiprocessing issues\n",
    "    collate_fn=rsna_collator\n",
    ")\n",
    "\n",
    "resnet_clf = MedCLIPModel(vision_cls=MedCLIPVisionModel)\n",
    "resnet_clf.from_pretrained()\n",
    "resnet_clf.cuda()\n",
    "\n",
    "rsna_classifier = PromptClassifier(\n",
    "    medclip_model=resnet_clf,\n",
    "    ensemble=True  \n",
    ")\n",
    "\n",
    "evaluator = Evaluator(\n",
    "    medclip_clf=rsna_classifier,\n",
    "    eval_dataloader=rsna_dataloader,\n",
    "    mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1c19b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the dataloader...\n",
      "Batch keys: dict_keys(['pixel_values', 'prompt_inputs', 'labels'])\n",
      "Pixel values shape: torch.Size([32, 3, 224, 224])\n",
      "Labels shape: torch.Size([32])\n",
      "Prompt inputs keys: dict_keys(['Pneumonia'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing the dataloader...\")\n",
    "test_batch = next(iter(rsna_dataloader))\n",
    "print(\"Batch keys:\", test_batch.keys())\n",
    "print(\"Pixel values shape:\", test_batch['pixel_values'].shape)\n",
    "print(\"Labels shape:\", test_batch['labels'].shape)\n",
    "print(\"Prompt inputs keys:\", test_batch['prompt_inputs'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c784d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running RSNA evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 945/945 [19:41<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {'pred': array([[0.2345862 ],\n",
      "       [0.37272498],\n",
      "       [0.30750567],\n",
      "       ...,\n",
      "       [0.28917682],\n",
      "       [0.2749958 ],\n",
      "       [0.3268345 ]], dtype=float32), 'labels': array([1, 1, 1, ..., 1, 1, 1], dtype=int64), 'auc': 0.3963176009270105, 'acc': 0.6838918847388097, 'precision': 0.34194594236940484, 'recall': 0.5, 'f1-score': 0.40613764514037604}\n",
      "accuracy: 0.6838918847388097\n",
      "precision: 0.34194594236940484\n",
      "recall: 0.5\n",
      "f1_score: 0.40613764514037604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "d:\\Conda\\envs\\entrep\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Conda\\envs\\entrep\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Conda\\envs\\entrep\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Run RSNA evaluation\n",
    "print(\"\\nRunning RSNA evaluation...\")\n",
    "try:\n",
    "    results = evaluator.evaluate()\n",
    "    print(f\"Results: {results}\")\n",
    "    print(f\"accuracy: {results['acc']}\")\n",
    "    print(f\"precision: {results['precision']}\")\n",
    "    print(f\"recall: {results['recall']}\")\n",
    "    print(f\"f1_score: {results['f1-score']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Evaluation failed with error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16e8829a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running RSNA evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 945/945 [16:14<00:00,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {'pred': array([[-1.2724408 ],\n",
      "       [-1.3392502 ],\n",
      "       [-0.9474664 ],\n",
      "       ...,\n",
      "       [-0.5673434 ],\n",
      "       [-0.48692712],\n",
      "       [-0.9549953 ]], dtype=float32), 'labels': array([1, 1, 1, ..., 1, 1, 1], dtype=int64), 'auc': 0.37604737492162854, 'acc': 0.3161081152611903, 'precision': 0.15805405763059516, 'recall': 0.5, 'f1-score': 0.24018400281534363}\n",
      "accuracy: 0.3161081152611903\n",
      "precision: 0.15805405763059516\n",
      "recall: 0.5\n",
      "f1_score: 0.24018400281534363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "d:\\Conda\\envs\\entrep\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Conda\\envs\\entrep\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Conda\\envs\\entrep\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Run RSNA evaluation\n",
    "print(\"\\nRunning RSNA evaluation...\")\n",
    "try:\n",
    "    results = evaluator.evaluate()\n",
    "    print(f\"Results: {results}\")\n",
    "    print(f\"accuracy: {results['acc']}\")\n",
    "    print(f\"precision: {results['precision']}\")\n",
    "    print(f\"recall: {results['recall']}\")\n",
    "    print(f\"f1_score: {results['f1-score']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Evaluation failed with error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34804816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entrep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
